# test_simple.py - Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¨Ø³Ø· Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
import torch
from config_system import CosmosAdvancedConfig
from cosmos_model_advanced import CosmosAdvancedModel

def test_basic_model():
    """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ"""
    print("Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ...")
    
    # Ø¥Ù†Ø´Ø§Ø¡ ØªÙƒÙˆÙŠÙ† Ù…Ø¨Ø³Ø·
    config = CosmosAdvancedConfig(
        dim=256,
        n_layers=2,
        n_heads=8,
        n_kv_heads=8,  # Ù†ÙØ³ Ø§Ù„Ø¹Ø¯Ø¯ Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„
        vocab_size=1000,
        max_sequence_length=1024
    )
    
    print(f"Ø§Ù„ØªÙ‡ÙŠØ¦Ø©:")
    print(f"  - Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯: {config.dim}")
    print(f"  - Ø§Ù„Ø·Ø¨Ù‚Ø§Øª: {config.n_layers}")
    print(f"  - Ø§Ù„Ø±Ø¤ÙˆØ³: {config.n_heads}")
    print(f"  - Ø±Ø¤ÙˆØ³ KV: {config.n_kv_heads}")
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    model = CosmosAdvancedModel(config)
    print(f"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­!")
    print(f"Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª: {model.total_params:,}")
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙ…Ø±ÙŠØ±
    batch_size = 2
    seq_len = 8
    input_ids = torch.randint(0, config.vocab_size, (batch_size, seq_len))
    
    print(f"Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙ…Ø±ÙŠØ±...")
    print(f"Ø´ÙƒÙ„ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„: {input_ids.shape}")
    
    model.eval()
    with torch.no_grad():
        try:
            # ØªÙ…Ø±ÙŠØ± Ø¨Ø³ÙŠØ· Ø¨Ø¯ÙˆÙ† Ù‚Ø¯Ø±Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©
            logits, diagnostics = model(
                input_ids,
                use_reasoning=False,
                use_memory=False,
                use_learning=False,
                use_safety=False,
                use_evaluation=False,
                return_diagnostics=True
            )
            
            print(f"âœ… Ù†Ø¬Ø­ Ø§Ù„ØªÙ…Ø±ÙŠØ±!")
            print(f"Ø´ÙƒÙ„ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬: {logits.shape}")
            if diagnostics and 'model_info' in diagnostics:
                print(f"Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…ØªÙˆÙØ±Ø©")
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ…Ø±ÙŠØ±: {e}")
            import traceback
            traceback.print_exc()

def test_with_reasoning():
    """Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹ Ù‚Ø¯Ø±Ø§Øª Ø§Ù„ØªÙÙƒÙŠØ±"""
    print("\nØ§Ø®ØªØ¨Ø§Ø± Ù…Ø¹ Ù‚Ø¯Ø±Ø§Øª Ø§Ù„ØªÙÙƒÙŠØ±...")
    
    config = CosmosAdvancedConfig(
        dim=512,
        n_layers=4,
        n_heads=8,
        n_kv_heads=8,  # Ù†ÙØ³ Ø§Ù„Ø¹Ø¯Ø¯ Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„
        vocab_size=2000,
        max_sequence_length=1024
    )
    
    model = CosmosAdvancedModel(config)
    model.eval()
    
    input_ids = torch.randint(0, config.vocab_size, (1, 10))
    
    with torch.no_grad():
        try:
            logits, diagnostics = model(
                input_ids,
                use_reasoning=True,
                use_memory=True,
                use_safety=False,
                use_evaluation=False,
                return_diagnostics=True
            )
            
            print(f"âœ… Ù†Ø¬Ø­ Ø§Ù„ØªÙ…Ø±ÙŠØ± Ù…Ø¹ Ø§Ù„ØªÙÙƒÙŠØ±!")
            print(f"Ø´ÙƒÙ„ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬: {logits.shape}")
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ…Ø±ÙŠØ± Ù…Ø¹ Ø§Ù„ØªÙÙƒÙŠØ±: {e}")
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    print("ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ù†Ù…ÙˆØ°Ø¬ Cosmos Ø§Ù„Ù…ØªÙ‚Ø¯Ù…\n")
    
    test_basic_model()
    test_with_reasoning()
    
    print("\nâœ… Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±!")